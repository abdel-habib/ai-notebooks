{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0162db-9f18-4398-b6a9-c30dd7f1d5fa",
   "metadata": {},
   "source": [
    "A script to train a nnU-Net V2 model, for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6155ce54-6421-4400-b429-221f02955746",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb98b9fa-bcdc-4f42-a818-37d5798df429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'available': True,\n",
       " 'count': 1,\n",
       " 'names': ['NVIDIA GeForce RTX 3060 Laptop GPU'],\n",
       " 'memory_gb': [5.99951171875],\n",
       " 'cuda_version': '12.6'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'platform': 'Linux',\n",
       " 'python_version': '3.10.12',\n",
       " 'torch_version': '2.7.0+cu126',\n",
       " 'cpu_count': 8,\n",
       " 'cpu_count_logical': 16,\n",
       " 'memory_gb': 7.6018829345703125}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.common import get_system_info, get_gpu_info\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "display(get_gpu_info())\n",
    "display(get_system_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b99684-424b-4b4f-8ebd-63ca5986bf40",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f62558c8-02d4-43e9-9f0b-e9cc67177a8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'nnUNet'...\n",
      "remote: Enumerating objects: 14008, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 14008 (delta 0), reused 3 (delta 0), pack-reused 14005 (from 1)\u001b[K\n",
      "Receiving objects: 100% (14008/14008), 8.61 MiB | 6.60 MiB/s, done.\n",
      "Resolving deltas: 100% (10702/10702), done.\n",
      "Updating files: 100% (246/246), done.\n",
      "Obtaining file:///mnt/c/Users/abdal/Documents/Projects/ai-notebooks/nnUNet\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting dynamic-network-architectures<0.5,>=0.4.1\n",
      "  Downloading dynamic_network_architectures-0.4.2.tar.gz (28 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting graphviz\n",
      "  Using cached graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: scipy in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from nnunetv2==2.6.2) (1.15.3)\n",
      "Collecting tifffile\n",
      "  Downloading tifffile-2025.5.10-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.5/226.5 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting batchgenerators>=0.25.1\n",
      "  Downloading batchgenerators-0.25.1.tar.gz (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting acvl-utils<0.3,>=0.2.3\n",
      "  Downloading acvl_utils-0.2.5.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from nnunetv2==2.6.2) (4.67.1)\n",
      "Collecting nibabel\n",
      "  Downloading nibabel-5.3.2-py3-none-any.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from nnunetv2==2.6.2) (3.10.3)\n",
      "Collecting blosc2>=3.0.0b1\n",
      "  Downloading blosc2-3.10.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: requests in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from nnunetv2==2.6.2) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from nnunetv2==2.6.2) (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.24 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from nnunetv2==2.6.2) (2.2.6)\n",
      "Collecting scikit-image>=0.19.3\n",
      "  Downloading scikit_image-0.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=2.1.2 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from nnunetv2==2.6.2) (2.7.0)\n",
      "Collecting imagecodecs\n",
      "  Downloading imagecodecs-2025.3.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from nnunetv2==2.6.2) (2.3.0)\n",
      "Requirement already satisfied: einops in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from nnunetv2==2.6.2) (0.8.1)\n",
      "Collecting yacs\n",
      "  Using cached yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Collecting batchgeneratorsv2>=0.3.0\n",
      "  Downloading batchgeneratorsv2-0.3.0.tar.gz (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: seaborn in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from nnunetv2==2.6.2) (0.13.2)\n",
      "Collecting SimpleITK>=2.2.1\n",
      "  Downloading simpleitk-2.5.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (52.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting connected-components-3d\n",
      "  Downloading connected_components_3d-3.26.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting future\n",
      "  Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow>=7.1.2 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.2) (11.2.1)\n",
      "Requirement already satisfied: threadpoolctl in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.2) (3.6.0)\n",
      "Collecting unittest2\n",
      "  Using cached unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n",
      "Collecting fft-conv-pytorch\n",
      "  Downloading fft_conv_pytorch-1.2.0-py3-none-any.whl (6.8 kB)\n",
      "Collecting msgpack\n",
      "  Downloading msgpack-1.1.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (406 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m406.1/406.1 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: platformdirs in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (4.3.8)\n",
      "Collecting ndindex\n",
      "  Downloading ndindex-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (501 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m501.6/501.6 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting py-cpuinfo\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting numexpr>=2.14.1\n",
      "  Downloading numexpr-2.14.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.2/440.2 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting timm\n",
      "  Downloading timm-1.0.21-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx>=3.0 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (3.4.2)\n",
      "Requirement already satisfied: packaging>=21 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (25.0)\n",
      "Collecting lazy-loader>=0.4\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (2.37.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (4.13.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (3.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.6.77)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.6.80)\n",
      "Requirement already satisfied: fsspec in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (0.6.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (1.14.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (2.26.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.6.4.1)\n",
      "Requirement already satisfied: filelock in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (3.18.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.6.77)\n",
      "Requirement already satisfied: jinja2 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from torch>=2.1.2->nnunetv2==2.6.2) (3.1.6)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from triton==3.3.0->torch>=2.1.2->nnunetv2==2.6.2) (59.6.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from matplotlib->nnunetv2==2.6.2) (1.4.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from matplotlib->nnunetv2==2.6.2) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from matplotlib->nnunetv2==2.6.2) (3.2.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from matplotlib->nnunetv2==2.6.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from matplotlib->nnunetv2==2.6.2) (4.58.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from matplotlib->nnunetv2==2.6.2) (2.9.0.post0)\n",
      "Collecting importlib-resources>=5.12\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from pandas->nnunetv2==2.6.2) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from pandas->nnunetv2==2.6.2) (2025.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from requests->nnunetv2==2.6.2) (2025.4.26)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from requests->nnunetv2==2.6.2) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from requests->nnunetv2==2.6.2) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from requests->nnunetv2==2.6.2) (3.10)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from scikit-learn->nnunetv2==2.6.2) (1.5.1)\n",
      "Requirement already satisfied: PyYAML in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from yacs->nnunetv2==2.6.2) (6.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->nnunetv2==2.6.2) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.1.2->nnunetv2==2.6.2) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from jinja2->torch>=2.1.2->nnunetv2==2.6.2) (3.0.2)\n",
      "Requirement already satisfied: safetensors in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (0.5.3)\n",
      "Requirement already satisfied: torchvision in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (0.22.0)\n",
      "Requirement already satisfied: huggingface_hub in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (0.33.2)\n",
      "Collecting argparse\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting traceback2\n",
      "  Using cached traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/lib/python3.10/site-packages (from huggingface_hub->timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (1.1.5)\n",
      "Collecting linecache2\n",
      "  Using cached linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n",
      "Using legacy 'setup.py install' for acvl-utils, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for batchgenerators, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for dynamic-network-architectures, since package 'wheel' is not installed.\n",
      "Building wheels for collected packages: nnunetv2, batchgeneratorsv2\n",
      "  Building editable for nnunetv2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nnunetv2: filename=nnunetv2-2.6.2-0.editable-py3-none-any.whl size=16871 sha256=84c9dd84aa4b5c8997af4f09753c7c110605fae461e87ea672632a4d9b9cbfb8\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-71h2blma/wheels/c9/d8/1b/cd9255a05863323ac62c7526c73fe60bcef63407315049005f\n",
      "  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for batchgeneratorsv2: filename=batchgeneratorsv2-0.3.0-py3-none-any.whl size=65215 sha256=e274f7c710778760ec8e50840f7fb6127f5440675c0386be26576b674725ad38\n",
      "  Stored in directory: /home/abdal/.cache/pip/wheels/85/91/18/f246cf6cecb275d0e293271390794a0c090621cfc1ab1501c7\n",
      "Successfully built nnunetv2 batchgeneratorsv2\n",
      "Installing collected packages: SimpleITK, py-cpuinfo, linecache2, argparse, yacs, traceback2, tifffile, numexpr, ndindex, msgpack, lazy-loader, importlib-resources, imagecodecs, graphviz, future, connected-components-3d, unittest2, scikit-image, nibabel, blosc2, batchgenerators, fft-conv-pytorch, acvl-utils, timm, batchgeneratorsv2, dynamic-network-architectures, nnunetv2\n",
      "  Running setup.py install for batchgenerators ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for acvl-utils ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for dynamic-network-architectures ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed SimpleITK-2.5.2 acvl-utils-0.2.5 argparse-1.4.0 batchgenerators-0.25.1 batchgeneratorsv2-0.3.0 blosc2-3.10.2 connected-components-3d-3.26.0 dynamic-network-architectures-0.4.2 fft-conv-pytorch-1.2.0 future-1.0.0 graphviz-0.21 imagecodecs-2025.3.30 importlib-resources-6.5.2 lazy-loader-0.4 linecache2-1.0.0 msgpack-1.1.2 ndindex-1.10.0 nibabel-5.3.2 nnunetv2-2.6.2 numexpr-2.14.1 py-cpuinfo-9.0.0 scikit-image-0.25.2 tifffile-2025.5.10 timm-1.0.21 traceback2-1.4.0 unittest2-1.1.0 yacs-0.1.8\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/installation_instructions.md\n",
    "# Run only once!\n",
    "# !git clone https://github.com/MIC-DKFZ/nnUNet.git\n",
    "# !cd nnUNet; pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd773bd-fa20-4f4c-b9db-89267fe83b31",
   "metadata": {},
   "source": [
    "#### nnunetv2 for 3D data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d9efba-1a0e-4c25-b636-560184de4484",
   "metadata": {},
   "source": [
    "Dataset formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42aeeef8-29ab-4e72-a7be-26ece4106079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/setting_up_paths.md\n",
    "# https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/dataset_format.md\n",
    "base_dir = os.getcwd()\n",
    "data_path = os.path.join(base_dir, 'data')\n",
    "nnUNet_raw = os.path.join(data_path, 'nnUNet_raw')\n",
    "\n",
    "# create nnunet_raw dir\n",
    "os.makedirs(nnUNet_raw, exist_ok=True)\n",
    "\n",
    "# IBSR18 (3D) dataset for brain tissue segmentation wil be used as an example\n",
    "# TODO: download the dataset into the data folder\n",
    "ibsr18_path = os.path.join(data_path, 'IBSR18')\n",
    "\n",
    "# nnUNet_raw: This is where you place the raw datasets. This folder will have one subfolder for each dataset names DatasetXXX_YYY \n",
    "# where XXX is a 3-digit identifier (such as 001, 002, 043, 999, ...) and YYY is the (unique) dataset name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e32537e8-dd3c-4e56-8959-ba04d5b25360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the new dataset folder with nnunet folder naming inside the nnUnet_raw folder\n",
    "os.makedirs(os.path.join(nnUNet_raw, 'Dataset001_IBSR18'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f93a6bf-8261-4de4-9f13-a9ddf2c6b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structuring the files inside the dataset folder\n",
    "# Note that this dataset has a single input channel (one modality type, for example, one of FLAIR, T1w, T1gd or T2w), thus we use _0000\n",
    "\n",
    "# Create new directory structure\n",
    "os.makedirs(os.path.join(nnUNet_raw, 'Dataset001_IBSR18', 'imagesTr'), exist_ok=True)\n",
    "os.makedirs(os.path.join(nnUNet_raw, 'Dataset001_IBSR18', 'imagesTs'), exist_ok=True)\n",
    "os.makedirs(os.path.join(nnUNet_raw, 'Dataset001_IBSR18', 'labelsTr'), exist_ok=True)\n",
    "\n",
    "# Function to handle the file copying and renaming\n",
    "def handle_files(source_folder, dest_path, is_test=False):\n",
    "    for folder_name in sorted(os.listdir(source_folder)):\n",
    "        folder_path = os.path.join(source_folder, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith('.nii.gz'):\n",
    "                    source_file = os.path.join(folder_path, file_name)\n",
    "                    if '_seg' in file_name:\n",
    "                        # For segmentation files (labels)\n",
    "                        dest_file = os.path.join(dest_path, 'labelsTr', folder_name + '.nii.gz')\n",
    "                    else:\n",
    "                        # For image files\n",
    "                        suffix = '_0000.nii.gz'\n",
    "                        dest_file = os.path.join(dest_path, 'imagesTs' if is_test else 'imagesTr', folder_name + suffix)\n",
    "                    shutil.copy2(source_file, dest_file)\n",
    "\n",
    "# Process each set\n",
    "# Here, 'Dataset001_IBSR18' is the newly named folder\n",
    "handle_files(source_folder=os.path.join(ibsr18_path, 'Training_Set'), dest_path=os.path.join(nnUNet_raw, 'Dataset001_IBSR18'))\n",
    "handle_files(source_folder=os.path.join(ibsr18_path, 'Validation_Set'), dest_path=os.path.join(nnUNet_raw, 'Dataset001_IBSR18'))\n",
    "handle_files(source_folder=os.path.join(ibsr18_path, 'Test_Set'), dest_path=os.path.join(nnUNet_raw, 'Dataset001_IBSR18'), is_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d93f2-27aa-40da-a03b-796ff3327ef5",
   "metadata": {},
   "source": [
    "From the nnUNet git repo: 'For each training case, all images must have the same geometry to ensure that their pixel arrays are aligned. Also make sure that all your data is co-registered!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e399c454-b8e9-46ec-ba21-6431b5d4f18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset JSON created successfully\n"
     ]
    }
   ],
   "source": [
    "# Creating the required json file\n",
    "def create_dataset_json(parent_dir):\n",
    "    # Define the structure of the JSON file\n",
    "    dataset_json = {\n",
    "        \"channel_names\": {\"0\": \"T1\"},\n",
    "        \"labels\": {\n",
    "            \"background\": 0,\n",
    "            \"CFS\": 1,\n",
    "            \"GM\": 2,\n",
    "            \"WM\": 3\n",
    "         }, \n",
    "        \"numTraining\": 0,\n",
    "        # \"numTest\": 0,\n",
    "        # \"training\": [],\n",
    "        # \"test\": [],\n",
    "        \"file_ending\": \".nii.gz\"\n",
    "    }\n",
    "\n",
    "    # Paths for training and test data\n",
    "    training_images_path = os.path.join(parent_dir, \"imagesTr\")\n",
    "    training_labels_path = os.path.join(parent_dir, \"labelsTr\")\n",
    "    test_images_path = os.path.join(parent_dir, \"imagesTs\")\n",
    "\n",
    "    # Scan for training images and labels\n",
    "    if os.path.exists(training_images_path) and os.path.exists(training_labels_path):\n",
    "        # training_images = sorted([f for f in os.listdir(training_images_path) if f.endswith('.nii.gz')])\n",
    "        training_labels = sorted([f for f in os.listdir(training_labels_path) if f.endswith('.nii.gz')])\n",
    "        # for img in training_labels:\n",
    "        #     dataset_json[\"training\"].append({\n",
    "        #             \"image\": os.path.join(\"./imagesTr\", img),\n",
    "        #             \"label\": os.path.join(\"./labelsTr\", img)\n",
    "        #         })\n",
    "        \n",
    "        dataset_json[\"numTraining\"] = len(training_labels)\n",
    "\n",
    "    # Scan for test images\n",
    "    # if os.path.exists(test_images_path):\n",
    "    #     test_images = sorted([f for f in os.listdir(test_images_path) if f.endswith('.nii.gz')])\n",
    "    #     for img in test_images:\n",
    "    #         dataset_json[\"test\"].append(os.path.join(\"./imagesTs\", img))\n",
    "        \n",
    "    #     dataset_json[\"numTest\"] = len(dataset_json[\"test\"])\n",
    "\n",
    "    # Write to JSON file\n",
    "    try:\n",
    "        with open(os.path.join(parent_dir, 'dataset.json'), 'w') as outfile:\n",
    "            json.dump(dataset_json, outfile, indent=4)\n",
    "            \n",
    "        print(f\"Dataset JSON created successfully\")\n",
    "    except IOError as e:\n",
    "        print(f\"Error creating JSON file: {e}\")\n",
    "\n",
    "create_dataset_json(os.path.join(nnUNet_raw, 'Dataset001_IBSR18'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b137a70-a53b-44d3-bc06-f85fdd39a926",
   "metadata": {},
   "source": [
    "Experiment planning and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "27f844f6-c275-405c-9ffc-e381d81a1cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nnUNet_raw = ... # already created before\n",
    "nnUNet_preprocessed = os.path.join(data_path,'nnUNet_preprocessed')\n",
    "results_folder = os.path.join(data_path,'nnUNet_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3928ee99-e206-4543-9c0c-e09f7fd21581",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"nnUNet_raw\"] = str(nnUNet_raw)\n",
    "os.environ[\"nnUNet_preprocessed\"] = str(nnUNet_preprocessed)\n",
    "os.environ[\"nnUNet_results\"] = str(results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f47c6c17-89cf-41a8-a200-a0e8a726c554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint extraction...\n",
      "Dataset001_IBSR18\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "\n",
      "####################\n",
      "verify_dataset_integrity Done. \n",
      "If you didn't see any error messages then your dataset is most likely OK!\n",
      "####################\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "100%|███████████████████████████████████████████| 15/15 [00:30<00:00,  2.05s/it]\n",
      "Experiment planning...\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [115. 139. 147.], 3d_lowres: [115, 139, 147]\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 69, 'patch_size': (np.int64(160), np.int64(160)), 'median_image_size_in_voxels': array([139., 147.]), 'spacing': array([0.9375, 0.9375]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (np.int64(112), np.int64(128), np.int64(160)), 'median_image_size_in_voxels': array([115., 139., 147.]), 'spacing': array([1.5   , 0.9375, 0.9375]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (1, 2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n",
      "\n",
      "Plans were saved to /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/data/nnUNet_preprocessed/Dataset001_IBSR18/nnUNetPlans.json\n",
      "Preprocessing...\n",
      "Preprocessing dataset Dataset001_IBSR18\n",
      "Configuration: 2d...\n",
      "100%|███████████████████████████████████████████| 15/15 [00:53<00:00,  3.56s/it]\n",
      "Configuration: 3d_fullres...\n",
      "100%|███████████████████████████████████████████| 15/15 [00:38<00:00,  2.57s/it]\n",
      "Configuration: 3d_lowres...\n",
      "INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset001_IBSR18. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# DATASET_ID=001 following the previous naming convention\n",
    "!nnUNetv2_plan_and_preprocess -d 001 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22886647-ae4f-4f2f-aaee-8f5b55f4c7fc",
   "metadata": {},
   "source": [
    "From the logs above, we notice the authors made an update to the planner. We can compare both approaches if GPU requirements were met.\n",
    "\n",
    "https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e68b71-65f9-4d3b-9810-24f76f9bb3f0",
   "metadata": {},
   "source": [
    "Model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a5e1590a-8705-4163-bb0f-ce7c5404d232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/FabianIsensee/hiddenlayer.git\n",
      "  Cloning https://github.com/FabianIsensee/hiddenlayer.git to /tmp/pip-req-build-sg8mqs9e\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/FabianIsensee/hiddenlayer.git /tmp/pip-req-build-sg8mqs9e\n",
      "  Resolved https://github.com/FabianIsensee/hiddenlayer.git to commit b7263b6dc4569da1b6dea5964e1eac78fa32fa77\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hUsing legacy 'setup.py install' for hiddenlayer, since package 'wheel' is not installed.\n",
      "Installing collected packages: hiddenlayer\n",
      "  Running setup.py install for hiddenlayer ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed hiddenlayer-0.2\n"
     ]
    }
   ],
   "source": [
    "# Optional: hiddenlayer enables nnU-net to generate plots of the network topologies it generates\n",
    "!pip install --upgrade git+https://github.com/FabianIsensee/hiddenlayer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4e60d338-b7b6-457a-8c43-7beba62745a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: nnUNetv2_train [-h] [-tr TR] [-p P]\n",
      "                      [-pretrained_weights PRETRAINED_WEIGHTS]\n",
      "                      [-num_gpus NUM_GPUS] [--npz] [--c] [--val] [--val_best]\n",
      "                      [--disable_checkpointing] [-device DEVICE]\n",
      "                      dataset_name_or_id configuration fold\n",
      "\n",
      "positional arguments:\n",
      "  dataset_name_or_id    Dataset name or ID to train with\n",
      "  configuration         Configuration that should be trained\n",
      "  fold                  Fold of the 5-fold cross-validation. Should be an int\n",
      "                        between 0 and 4.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -tr TR                [OPTIONAL] Use this flag to specify a custom trainer.\n",
      "                        Default: nnUNetTrainer\n",
      "  -p P                  [OPTIONAL] Use this flag to specify a custom plans\n",
      "                        identifier. Default: nnUNetPlans\n",
      "  -pretrained_weights PRETRAINED_WEIGHTS\n",
      "                        [OPTIONAL] path to nnU-Net checkpoint file to be used\n",
      "                        as pretrained model. Will only be used when actually\n",
      "                        training. Beta. Use with caution.\n",
      "  -num_gpus NUM_GPUS    Specify the number of GPUs to use for training\n",
      "  --npz                 [OPTIONAL] Save softmax predictions from final\n",
      "                        validation as npz files (in addition to predicted\n",
      "                        segmentations). Needed for finding the best ensemble.\n",
      "  --c                   [OPTIONAL] Continue training from latest checkpoint\n",
      "  --val                 [OPTIONAL] Set this flag to only run the validation.\n",
      "                        Requires training to have finished.\n",
      "  --val_best            [OPTIONAL] If set, the validation will be performed\n",
      "                        with the checkpoint_best instead of checkpoint_final.\n",
      "                        NOT COMPATIBLE with --disable_checkpointing! WARNING:\n",
      "                        This will use the same 'validation' folder as the\n",
      "                        regular validation with no way of distinguishing the\n",
      "                        two!\n",
      "  --disable_checkpointing\n",
      "                        [OPTIONAL] Set this flag to disable checkpointing.\n",
      "                        Ideal for testing things out and you dont want to\n",
      "                        flood your hard drive with checkpoints.\n",
      "  -device DEVICE        Use this to set the device the training should run\n",
      "                        with. Available options are 'cuda' (GPU), 'cpu' (CPU)\n",
      "                        and 'mps' (Apple M1/M2). Do NOT use this to set which\n",
      "                        GPU ID! Use CUDA_VISIBLE_DEVICES=X nnUNetv2_train\n",
      "                        [...] instead!\n"
     ]
    }
   ],
   "source": [
    "# hiddenlayer enables nnU-net to generate plots of the network topologies it generates\n",
    "!nnUNetv2_train -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "823354d7-2e87-41dc-b32b-e5040b7882a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a custom trainer to train for less amount of epochs, the nnUNetTrainer has 1000 epochs \n",
    "# nnUNet\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py\n",
    "\n",
    "# IMPORTANT\n",
    "# To avoid any training error with this trainer, we will need to move it in nnunetv2.training.nnUNetTrainer (../nnUNet/nnunetv2/training/nnUNetTrainer). \n",
    "\n",
    "# add the path to the cloned nnUNet folder to avoid any imports issues in the next trainer cell\n",
    "# the code below is no longer needed to be in the notebook, just copy the trainer into a new trainer file in the nnunetv2.training.nnUNetTrainer as \n",
    "# mentioned above and configure the custom trainer there\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# import sys, os\n",
    "# sys.path.append(os.path.abspath(\"nnUNet\"))\n",
    "\n",
    "# from nnunetv2.training.nnUNetTrainer.nnUNetTrainer import nnUNetTrainer\n",
    "# class nnUNetTrainer_Fast(nnUNetTrainer):\n",
    "#     def __init__(self, plans: dict, configuration: str, fold: int, dataset_json: dict, device: torch.device = torch.device('cuda')):\n",
    "#         super().__init__(plans, configuration, fold, dataset_json, device)\n",
    "#         # IMPORTANT: checkpoints are saved every 50 epochs, if epochs < 10, we won't be able to continue training the trained fold \n",
    "#         self.num_epochs = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5298e56e-a6c7-44a1-893b-ef829d354b28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-10-27 23:41:49.307967: Using torch.compile...\n",
      "2025-10-27 23:41:52.035894: do_dummy_2d_data_aug: False\n",
      "2025-10-27 23:41:52.044960: Using splits from existing split file: /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/data/nnUNet_preprocessed/Dataset001_IBSR18/splits_final.json\n",
      "2025-10-27 23:41:52.052359: The split file contains 5 splits.\n",
      "2025-10-27 23:41:52.058054: Desired fold for training: 0\n",
      "2025-10-27 23:41:52.063931: This split has 12 training and 3 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 2d\n",
      " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 69, 'patch_size': [160, 160], 'median_image_size_in_voxels': [139.0, 147.0], 'spacing': [0.9375, 0.9375], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset001_IBSR18', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.5, 0.9375, 0.9375], 'original_median_shape_after_transp': [115, 137, 144], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 782.0, 'mean': 91.25938415527344, 'median': 69.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 602.0, 'std': 99.86860656738281}}} \n",
      "\n",
      "2025-10-27 23:42:03.238904: Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "2025-10-27 23:42:03.658609: \n",
      "2025-10-27 23:42:03.679245: Epoch 0\n",
      "2025-10-27 23:42:03.697837: Current learning rate: 0.01\n",
      "2025-10-27 23:44:55.379877: train_loss -0.28\n",
      "2025-10-27 23:44:55.395302: val_loss -0.6457\n",
      "2025-10-27 23:44:55.405156: Pseudo dice [np.float32(0.7354), np.float32(0.8972), np.float32(0.8799)]\n",
      "2025-10-27 23:44:55.417174: Epoch time: 171.72 s\n",
      "2025-10-27 23:44:55.430478: Yayy! New best EMA pseudo Dice: 0.8374999761581421\n",
      "2025-10-27 23:44:59.042554: \n",
      "2025-10-27 23:44:59.053650: Epoch 1\n",
      "2025-10-27 23:44:59.066594: Current learning rate: 0.0091\n",
      "2025-10-27 23:47:26.981319: train_loss -0.688\n",
      "2025-10-27 23:47:26.994076: val_loss -0.7642\n",
      "2025-10-27 23:47:27.004290: Pseudo dice [np.float32(0.8776), np.float32(0.9215), np.float32(0.9065)]\n",
      "2025-10-27 23:47:27.017321: Epoch time: 147.94 s\n",
      "2025-10-27 23:47:27.031600: Yayy! New best EMA pseudo Dice: 0.8439000248908997\n",
      "2025-10-27 23:47:30.148441: \n",
      "2025-10-27 23:47:30.157174: Epoch 2\n",
      "2025-10-27 23:47:30.165442: Current learning rate: 0.00818\n",
      "2025-10-27 23:49:49.572657: train_loss -0.7599\n",
      "2025-10-27 23:49:49.585055: val_loss -0.7977\n",
      "2025-10-27 23:49:49.596615: Pseudo dice [np.float32(0.8994), np.float32(0.9295), np.float32(0.917)]\n",
      "2025-10-27 23:49:49.606344: Epoch time: 139.43 s\n",
      "2025-10-27 23:49:49.614693: Yayy! New best EMA pseudo Dice: 0.8511000275611877\n",
      "2025-10-27 23:49:52.879328: \n",
      "2025-10-27 23:49:52.886073: Epoch 3\n",
      "2025-10-27 23:49:52.894315: Current learning rate: 0.00725\n",
      "2025-10-27 23:52:39.675045: train_loss -0.7883\n",
      "2025-10-27 23:52:39.688836: val_loss -0.8138\n",
      "2025-10-27 23:52:39.699779: Pseudo dice [np.float32(0.9074), np.float32(0.9346), np.float32(0.9238)]\n",
      "2025-10-27 23:52:39.711939: Epoch time: 166.8 s\n",
      "2025-10-27 23:52:39.723392: Yayy! New best EMA pseudo Dice: 0.8582000136375427\n",
      "2025-10-27 23:52:43.611898: \n",
      "2025-10-27 23:52:43.620259: Epoch 4\n",
      "2025-10-27 23:52:43.633464: Current learning rate: 0.00631\n",
      "2025-10-27 23:55:07.174934: train_loss -0.8015\n",
      "2025-10-27 23:55:07.186052: val_loss -0.8239\n",
      "2025-10-27 23:55:07.195660: Pseudo dice [np.float32(0.9093), np.float32(0.9376), np.float32(0.928)]\n",
      "2025-10-27 23:55:07.207832: Epoch time: 143.56 s\n",
      "2025-10-27 23:55:07.218517: Yayy! New best EMA pseudo Dice: 0.864799976348877\n",
      "2025-10-27 23:55:10.520175: \n",
      "2025-10-27 23:55:10.528546: Epoch 5\n",
      "2025-10-27 23:55:10.535937: Current learning rate: 0.00536\n",
      "2025-10-27 23:57:30.248180: train_loss -0.8118\n",
      "2025-10-27 23:57:30.259266: val_loss -0.8312\n",
      "2025-10-27 23:57:30.270201: Pseudo dice [np.float32(0.914), np.float32(0.9394), np.float32(0.9307)]\n",
      "2025-10-27 23:57:30.283045: Epoch time: 139.73 s\n",
      "2025-10-27 23:57:30.292595: Yayy! New best EMA pseudo Dice: 0.8712000250816345\n",
      "2025-10-27 23:57:33.727182: \n",
      "2025-10-27 23:57:33.734895: Epoch 6\n",
      "2025-10-27 23:57:33.741443: Current learning rate: 0.00438\n",
      "2025-10-27 23:59:54.385209: train_loss -0.818\n",
      "2025-10-27 23:59:54.396874: val_loss -0.8356\n",
      "2025-10-27 23:59:54.409284: Pseudo dice [np.float32(0.9168), np.float32(0.9411), np.float32(0.9333)]\n",
      "2025-10-27 23:59:54.421318: Epoch time: 140.66 s\n",
      "2025-10-27 23:59:54.429750: Yayy! New best EMA pseudo Dice: 0.8770999908447266\n",
      "2025-10-27 23:59:57.743882: \n",
      "2025-10-27 23:59:57.750506: Epoch 7\n",
      "2025-10-27 23:59:57.757493: Current learning rate: 0.00338\n",
      "2025-10-28 00:02:19.017878: train_loss -0.8233\n",
      "2025-10-28 00:02:19.028347: val_loss -0.8376\n",
      "2025-10-28 00:02:19.039160: Pseudo dice [np.float32(0.9178), np.float32(0.9418), np.float32(0.9341)]\n",
      "2025-10-28 00:02:19.054585: Epoch time: 141.27 s\n",
      "2025-10-28 00:02:19.066745: Yayy! New best EMA pseudo Dice: 0.8824999928474426\n",
      "2025-10-28 00:02:22.568202: \n",
      "2025-10-28 00:02:22.574970: Epoch 8\n",
      "2025-10-28 00:02:22.582515: Current learning rate: 0.00235\n",
      "2025-10-28 00:04:43.063684: train_loss -0.8264\n",
      "2025-10-28 00:04:43.073595: val_loss -0.8397\n",
      "2025-10-28 00:04:43.085092: Pseudo dice [np.float32(0.9167), np.float32(0.9425), np.float32(0.9353)]\n",
      "2025-10-28 00:04:43.096693: Epoch time: 140.5 s\n",
      "2025-10-28 00:04:43.110442: Yayy! New best EMA pseudo Dice: 0.8873999714851379\n",
      "2025-10-28 00:04:48.751662: \n",
      "2025-10-28 00:04:48.757868: Epoch 9\n",
      "2025-10-28 00:04:48.763650: Current learning rate: 0.00126\n",
      "2025-10-28 00:07:08.673505: train_loss -0.829\n",
      "2025-10-28 00:07:08.685504: val_loss -0.8379\n",
      "2025-10-28 00:07:08.697588: Pseudo dice [np.float32(0.9167), np.float32(0.9423), np.float32(0.9344)]\n",
      "2025-10-28 00:07:08.708648: Epoch time: 139.92 s\n",
      "2025-10-28 00:07:08.720937: Yayy! New best EMA pseudo Dice: 0.8917999863624573\n",
      "2025-10-28 00:07:13.227042: Training done.\n",
      "2025-10-28 00:07:13.330968: Using splits from existing split file: /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/data/nnUNet_preprocessed/Dataset001_IBSR18/splits_final.json\n",
      "2025-10-28 00:07:13.351215: The split file contains 5 splits.\n",
      "2025-10-28 00:07:13.356731: Desired fold for training: 0\n",
      "2025-10-28 00:07:13.367275: This split has 12 training and 3 validation cases.\n",
      "2025-10-28 00:07:13.379464: predicting IBSR_01\n",
      "2025-10-28 00:07:13.665951: IBSR_01, shape torch.Size([1, 117, 139, 145]), rank 0\n",
      "2025-10-28 00:07:22.990099: predicting IBSR_09\n",
      "2025-10-28 00:07:23.813627: IBSR_09, shape torch.Size([1, 115, 147, 147]), rank 0\n",
      "2025-10-28 00:07:27.279078: predicting IBSR_14\n",
      "2025-10-28 00:07:27.700361: IBSR_14, shape torch.Size([1, 116, 144, 146]), rank 0\n",
      "2025-10-28 00:09:07.883382: Validation complete\n",
      "2025-10-28 00:09:07.891773: Mean Validation Dice:  0.9354187910297957\n"
     ]
    }
   ],
   "source": [
    "# configuration 2d (a 2D U-Net for 2D and 3D datasets)\n",
    "# nnU-Net stores a checkpoint every 50 epochs. If you need to continue a previous training, just add a --c to the training command.\n",
    "# IMPORTANT: If you plan to use nnUNetv2_find_best_configuration (see below) add the --npz flag\n",
    "# For FOLD in [0, 1, 2, 3, 4], run:\n",
    "# !nnUNetv2_train DATASET_NAME_OR_ID 2d FOLD [--npz]\n",
    "\n",
    "# IMPORTANT\n",
    "# --c flag works per FOLD, thus each fold is trained independently and doesn't train folds in sequence\n",
    "\n",
    "# if you trained a fold for 50 epochs, the trainer self.num_epochs value has to be updated (> than prev. value) to continue training further\n",
    "# for example: if you trained FOLD 0 for 51 epochs (0-50 idx as the count starts from 0), changing self.num_epochs to 52 will start the epoch counter \n",
    "# in the logs from 51 (52 - 1 for 0th convention) and train for a single epoch.\n",
    "\n",
    "# good to train a FOLD for many epochs as an experiment first and observe the loss curves, gives an idea on a good self.num_epochs value and could \n",
    "# prevent overfitting\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Training script; results file is created automatically\n",
    "!nnUNetv2_train Dataset001_IBSR18 2d 0 -tr nnUNetTrainer_Fast --npz # FOLD 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d966ec79-b9bc-472e-b49f-fa26bb6e5105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-10-28 00:11:41.808169: Using torch.compile...\n",
      "2025-10-28 00:11:45.169210: do_dummy_2d_data_aug: False\n",
      "2025-10-28 00:11:45.177801: Using splits from existing split file: /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/data/nnUNet_preprocessed/Dataset001_IBSR18/splits_final.json\n",
      "2025-10-28 00:11:45.185642: The split file contains 5 splits.\n",
      "2025-10-28 00:11:45.190823: Desired fold for training: 1\n",
      "2025-10-28 00:11:45.196307: This split has 12 training and 3 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 2d\n",
      " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 69, 'patch_size': [160, 160], 'median_image_size_in_voxels': [139.0, 147.0], 'spacing': [0.9375, 0.9375], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset001_IBSR18', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.5, 0.9375, 0.9375], 'original_median_shape_after_transp': [115, 137, 144], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 782.0, 'mean': 91.25938415527344, 'median': 69.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 602.0, 'std': 99.86860656738281}}} \n",
      "\n",
      "2025-10-28 00:11:55.513132: Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "2025-10-28 00:11:55.951437: \n",
      "2025-10-28 00:11:55.975959: Epoch 0\n",
      "2025-10-28 00:11:56.000722: Current learning rate: 0.01\n",
      "2025-10-28 00:14:45.348538: train_loss -0.2349\n",
      "2025-10-28 00:14:45.375397: val_loss -0.4979\n",
      "2025-10-28 00:14:45.384049: Pseudo dice [np.float32(0.0), np.float32(0.8793), np.float32(0.8882)]\n",
      "2025-10-28 00:14:45.399392: Epoch time: 169.4 s\n",
      "2025-10-28 00:14:45.407795: Yayy! New best EMA pseudo Dice: 0.5891000032424927\n",
      "2025-10-28 00:14:48.788851: \n",
      "2025-10-28 00:14:48.798284: Epoch 1\n",
      "2025-10-28 00:14:48.808248: Current learning rate: 0.0091\n",
      "2025-10-28 00:17:02.509933: train_loss -0.617\n",
      "2025-10-28 00:17:02.521322: val_loss -0.7341\n",
      "2025-10-28 00:17:02.533303: Pseudo dice [np.float32(0.8642), np.float32(0.904), np.float32(0.911)]\n",
      "2025-10-28 00:17:02.547424: Epoch time: 133.72 s\n",
      "2025-10-28 00:17:02.559126: Yayy! New best EMA pseudo Dice: 0.6194999814033508\n",
      "2025-10-28 00:17:05.732710: \n",
      "2025-10-28 00:17:05.744005: Epoch 2\n",
      "2025-10-28 00:17:05.752104: Current learning rate: 0.00818\n",
      "2025-10-28 00:19:19.377883: train_loss -0.7569\n",
      "2025-10-28 00:19:19.388227: val_loss -0.7762\n",
      "2025-10-28 00:19:19.399670: Pseudo dice [np.float32(0.8811), np.float32(0.915), np.float32(0.9214)]\n",
      "2025-10-28 00:19:19.412156: Epoch time: 133.65 s\n",
      "2025-10-28 00:19:19.423125: Yayy! New best EMA pseudo Dice: 0.6481999754905701\n",
      "2025-10-28 00:19:22.580593: \n",
      "2025-10-28 00:19:22.590147: Epoch 3\n",
      "2025-10-28 00:19:22.598684: Current learning rate: 0.00725\n",
      "2025-10-28 00:21:36.355031: train_loss -0.7879\n",
      "2025-10-28 00:21:36.367226: val_loss -0.7924\n",
      "2025-10-28 00:21:36.378358: Pseudo dice [np.float32(0.8821), np.float32(0.9221), np.float32(0.9268)]\n",
      "2025-10-28 00:21:36.392284: Epoch time: 133.78 s\n",
      "2025-10-28 00:21:36.404822: Yayy! New best EMA pseudo Dice: 0.6743999719619751\n",
      "2025-10-28 00:21:39.489078: \n",
      "2025-10-28 00:21:39.496571: Epoch 4\n",
      "2025-10-28 00:21:39.503405: Current learning rate: 0.00631\n",
      "2025-10-28 00:23:53.504392: train_loss -0.8031\n",
      "2025-10-28 00:23:53.517382: val_loss -0.8001\n",
      "2025-10-28 00:23:53.527569: Pseudo dice [np.float32(0.8875), np.float32(0.923), np.float32(0.93)]\n",
      "2025-10-28 00:23:53.539912: Epoch time: 134.02 s\n",
      "2025-10-28 00:23:53.553209: Yayy! New best EMA pseudo Dice: 0.6983000040054321\n",
      "2025-10-28 00:23:56.719912: \n",
      "2025-10-28 00:23:56.726911: Epoch 5\n",
      "2025-10-28 00:23:56.735887: Current learning rate: 0.00536\n",
      "2025-10-28 00:26:11.443374: train_loss -0.8136\n",
      "2025-10-28 00:26:11.456475: val_loss -0.8057\n",
      "2025-10-28 00:26:11.466120: Pseudo dice [np.float32(0.8906), np.float32(0.9255), np.float32(0.931)]\n",
      "2025-10-28 00:26:11.476542: Epoch time: 134.72 s\n",
      "2025-10-28 00:26:11.484986: Yayy! New best EMA pseudo Dice: 0.7200000286102295\n",
      "2025-10-28 00:26:14.562783: \n",
      "2025-10-28 00:26:14.570112: Epoch 6\n",
      "2025-10-28 00:26:14.577181: Current learning rate: 0.00438\n",
      "2025-10-28 00:28:26.313491: train_loss -0.8207\n",
      "2025-10-28 00:28:26.324075: val_loss -0.8083\n",
      "2025-10-28 00:28:26.335625: Pseudo dice [np.float32(0.8903), np.float32(0.9265), np.float32(0.9318)]\n",
      "2025-10-28 00:28:26.344583: Epoch time: 131.75 s\n",
      "2025-10-28 00:28:26.357965: Yayy! New best EMA pseudo Dice: 0.7397000193595886\n",
      "2025-10-28 00:28:29.457797: \n",
      "2025-10-28 00:28:29.465826: Epoch 7\n",
      "2025-10-28 00:28:29.473283: Current learning rate: 0.00338\n",
      "2025-10-28 00:30:43.552232: train_loss -0.825\n",
      "2025-10-28 00:30:43.562212: val_loss -0.8111\n",
      "2025-10-28 00:30:43.575778: Pseudo dice [np.float32(0.8922), np.float32(0.9273), np.float32(0.9336)]\n",
      "2025-10-28 00:30:43.584493: Epoch time: 134.1 s\n",
      "2025-10-28 00:30:43.594119: Yayy! New best EMA pseudo Dice: 0.7574999928474426\n",
      "2025-10-28 00:30:46.580636: \n",
      "2025-10-28 00:30:46.588374: Epoch 8\n",
      "2025-10-28 00:30:46.598672: Current learning rate: 0.00235\n",
      "2025-10-28 00:32:59.735370: train_loss -0.828\n",
      "2025-10-28 00:32:59.745486: val_loss -0.8148\n",
      "2025-10-28 00:32:59.755714: Pseudo dice [np.float32(0.8936), np.float32(0.9285), np.float32(0.9348)]\n",
      "2025-10-28 00:32:59.769714: Epoch time: 133.16 s\n",
      "2025-10-28 00:32:59.781068: Yayy! New best EMA pseudo Dice: 0.7735999822616577\n",
      "2025-10-28 00:33:05.185769: \n",
      "2025-10-28 00:33:05.194376: Epoch 9\n",
      "2025-10-28 00:33:05.201254: Current learning rate: 0.00126\n",
      "2025-10-28 00:35:18.281981: train_loss -0.83\n",
      "2025-10-28 00:35:18.295533: val_loss -0.8157\n",
      "2025-10-28 00:35:18.308275: Pseudo dice [np.float32(0.8918), np.float32(0.9294), np.float32(0.9352)]\n",
      "2025-10-28 00:35:18.318611: Epoch time: 133.1 s\n",
      "2025-10-28 00:35:18.334702: Yayy! New best EMA pseudo Dice: 0.788100004196167\n",
      "2025-10-28 00:35:22.823418: Training done.\n",
      "2025-10-28 00:35:22.971293: Using splits from existing split file: /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/data/nnUNet_preprocessed/Dataset001_IBSR18/splits_final.json\n",
      "2025-10-28 00:35:22.982966: The split file contains 5 splits.\n",
      "2025-10-28 00:35:22.995708: Desired fold for training: 1\n",
      "2025-10-28 00:35:23.003702: This split has 12 training and 3 validation cases.\n",
      "2025-10-28 00:35:23.027664: predicting IBSR_05\n",
      "2025-10-28 00:35:23.329640: IBSR_05, shape torch.Size([1, 115, 137, 140]), rank 0\n",
      "2025-10-28 00:35:31.662981: predicting IBSR_08\n",
      "2025-10-28 00:35:32.261195: IBSR_08, shape torch.Size([1, 109, 139, 144]), rank 0\n",
      "2025-10-28 00:35:34.585059: predicting IBSR_11\n",
      "2025-10-28 00:35:35.227332: IBSR_11, shape torch.Size([1, 109, 139, 154]), rank 0\n",
      "2025-10-28 00:37:17.592524: Validation complete\n",
      "2025-10-28 00:37:17.603545: Mean Validation Dice:  0.9240291959412167\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_train Dataset001_IBSR18 2d 1 -tr nnUNetTrainer_Fast --npz # FOLD 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ac229ae3-5a5f-4726-9f17-91ba06e1894c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-10-28 00:38:55.987139: Using torch.compile...\n",
      "2025-10-28 00:38:58.620213: do_dummy_2d_data_aug: False\n",
      "2025-10-28 00:38:58.633862: Using splits from existing split file: /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/data/nnUNet_preprocessed/Dataset001_IBSR18/splits_final.json\n",
      "2025-10-28 00:38:58.641392: The split file contains 5 splits.\n",
      "2025-10-28 00:38:58.647267: Desired fold for training: 2\n",
      "2025-10-28 00:38:58.651691: This split has 12 training and 3 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 2d\n",
      " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 69, 'patch_size': [160, 160], 'median_image_size_in_voxels': [139.0, 147.0], 'spacing': [0.9375, 0.9375], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset001_IBSR18', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.5, 0.9375, 0.9375], 'original_median_shape_after_transp': [115, 137, 144], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 782.0, 'mean': 91.25938415527344, 'median': 69.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 602.0, 'std': 99.86860656738281}}} \n",
      "\n",
      "2025-10-28 00:39:10.578655: Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "2025-10-28 00:39:11.018121: \n",
      "2025-10-28 00:39:11.036126: Epoch 0\n",
      "2025-10-28 00:39:11.056880: Current learning rate: 0.01\n",
      "2025-10-28 00:41:56.259556: train_loss -0.2961\n",
      "2025-10-28 00:41:56.272755: val_loss -0.6115\n",
      "2025-10-28 00:41:56.286871: Pseudo dice [np.float32(0.7168), np.float32(0.9011), np.float32(0.8615)]\n",
      "2025-10-28 00:41:56.300156: Epoch time: 165.24 s\n",
      "2025-10-28 00:41:56.312624: Yayy! New best EMA pseudo Dice: 0.8264999985694885\n",
      "2025-10-28 00:41:59.844570: \n",
      "2025-10-28 00:41:59.854871: Epoch 1\n",
      "2025-10-28 00:41:59.864271: Current learning rate: 0.0091\n",
      "2025-10-28 00:44:15.956785: train_loss -0.7044\n",
      "2025-10-28 00:44:15.968442: val_loss -0.7263\n",
      "2025-10-28 00:44:15.981962: Pseudo dice [np.float32(0.8345), np.float32(0.9195), np.float32(0.8882)]\n",
      "2025-10-28 00:44:15.995609: Epoch time: 136.11 s\n",
      "2025-10-28 00:44:16.008381: Yayy! New best EMA pseudo Dice: 0.8319000005722046\n",
      "2025-10-28 00:44:19.922675: \n",
      "2025-10-28 00:44:19.933088: Epoch 2\n",
      "2025-10-28 00:44:19.945893: Current learning rate: 0.00818\n",
      "2025-10-28 00:46:37.051184: train_loss -0.7681\n",
      "2025-10-28 00:46:37.060875: val_loss -0.7651\n",
      "2025-10-28 00:46:37.069987: Pseudo dice [np.float32(0.8558), np.float32(0.929), np.float32(0.9017)]\n",
      "2025-10-28 00:46:37.082456: Epoch time: 137.13 s\n",
      "2025-10-28 00:46:37.094747: Yayy! New best EMA pseudo Dice: 0.8382999897003174\n",
      "2025-10-28 00:46:40.271716: \n",
      "2025-10-28 00:46:40.279235: Epoch 3\n",
      "2025-10-28 00:46:40.285957: Current learning rate: 0.00725\n",
      "2025-10-28 00:48:55.639328: train_loss -0.7917\n",
      "2025-10-28 00:48:55.651384: val_loss -0.7817\n",
      "2025-10-28 00:48:55.660753: Pseudo dice [np.float32(0.8561), np.float32(0.9348), np.float32(0.9113)]\n",
      "2025-10-28 00:48:55.674302: Epoch time: 135.37 s\n",
      "2025-10-28 00:48:55.685879: Yayy! New best EMA pseudo Dice: 0.8445000052452087\n",
      "2025-10-28 00:48:58.740467: \n",
      "2025-10-28 00:48:58.749687: Epoch 4\n",
      "2025-10-28 00:48:58.759459: Current learning rate: 0.00631\n",
      "2025-10-28 00:51:15.423399: train_loss -0.8039\n",
      "2025-10-28 00:51:15.434459: val_loss -0.7893\n",
      "2025-10-28 00:51:15.445150: Pseudo dice [np.float32(0.8602), np.float32(0.9368), np.float32(0.9129)]\n",
      "2025-10-28 00:51:15.461600: Epoch time: 136.68 s\n",
      "2025-10-28 00:51:15.472023: Yayy! New best EMA pseudo Dice: 0.8503999710083008\n",
      "2025-10-28 00:51:18.720572: \n",
      "2025-10-28 00:51:18.728245: Epoch 5\n",
      "2025-10-28 00:51:18.734984: Current learning rate: 0.00536\n",
      "2025-10-28 00:53:37.128076: train_loss -0.8144\n",
      "2025-10-28 00:53:37.139518: val_loss -0.7997\n",
      "2025-10-28 00:53:37.149084: Pseudo dice [np.float32(0.8714), np.float32(0.9385), np.float32(0.9161)]\n",
      "2025-10-28 00:53:37.161478: Epoch time: 138.41 s\n",
      "2025-10-28 00:53:37.173260: Yayy! New best EMA pseudo Dice: 0.8561999797821045\n",
      "2025-10-28 00:53:40.152647: \n",
      "2025-10-28 00:53:40.160627: Epoch 6\n",
      "2025-10-28 00:53:40.168378: Current learning rate: 0.00438\n",
      "2025-10-28 00:55:58.035014: train_loss -0.821\n",
      "2025-10-28 00:55:58.047671: val_loss -0.7957\n",
      "2025-10-28 00:55:58.059653: Pseudo dice [np.float32(0.8632), np.float32(0.9383), np.float32(0.9156)]\n",
      "2025-10-28 00:55:58.072297: Epoch time: 137.88 s\n",
      "2025-10-28 00:55:58.083387: Yayy! New best EMA pseudo Dice: 0.8611999750137329\n",
      "2025-10-28 00:56:01.043374: \n",
      "2025-10-28 00:56:01.054622: Epoch 7\n",
      "2025-10-28 00:56:01.067445: Current learning rate: 0.00338\n",
      "2025-10-28 00:58:20.574311: train_loss -0.8241\n",
      "2025-10-28 00:58:20.586982: val_loss -0.8061\n",
      "2025-10-28 00:58:20.600218: Pseudo dice [np.float32(0.8734), np.float32(0.9404), np.float32(0.9195)]\n",
      "2025-10-28 00:58:20.611322: Epoch time: 139.53 s\n",
      "2025-10-28 00:58:20.623793: Yayy! New best EMA pseudo Dice: 0.8661999702453613\n",
      "2025-10-28 00:58:23.760079: \n",
      "2025-10-28 00:58:23.767825: Epoch 8\n",
      "2025-10-28 00:58:23.776481: Current learning rate: 0.00235\n",
      "2025-10-28 01:00:41.265568: train_loss -0.8288\n",
      "2025-10-28 01:00:41.276974: val_loss -0.807\n",
      "2025-10-28 01:00:41.287165: Pseudo dice [np.float32(0.8761), np.float32(0.9408), np.float32(0.9196)]\n",
      "2025-10-28 01:00:41.300138: Epoch time: 137.51 s\n",
      "2025-10-28 01:00:41.312403: Yayy! New best EMA pseudo Dice: 0.8708000183105469\n",
      "2025-10-28 01:00:46.177205: \n",
      "2025-10-28 01:00:46.184885: Epoch 9\n",
      "2025-10-28 01:00:46.190782: Current learning rate: 0.00126\n",
      "2025-10-28 01:03:06.234661: train_loss -0.8307\n",
      "2025-10-28 01:03:06.250323: val_loss -0.8087\n",
      "2025-10-28 01:03:06.259976: Pseudo dice [np.float32(0.8757), np.float32(0.9415), np.float32(0.9199)]\n",
      "2025-10-28 01:03:06.270876: Epoch time: 140.06 s\n",
      "2025-10-28 01:03:06.285128: Yayy! New best EMA pseudo Dice: 0.8748999834060669\n",
      "2025-10-28 01:03:10.799915: Training done.\n",
      "2025-10-28 01:03:10.887065: Using splits from existing split file: /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/data/nnUNet_preprocessed/Dataset001_IBSR18/splits_final.json\n",
      "2025-10-28 01:03:10.897875: The split file contains 5 splits.\n",
      "2025-10-28 01:03:10.908336: Desired fold for training: 2\n",
      "2025-10-28 01:03:10.916735: This split has 12 training and 3 validation cases.\n",
      "2025-10-28 01:03:10.927816: predicting IBSR_13\n",
      "2025-10-28 01:03:11.231571: IBSR_13, shape torch.Size([1, 115, 136, 149]), rank 0\n",
      "2025-10-28 01:03:20.897078: predicting IBSR_16\n",
      "2025-10-28 01:03:21.469023: IBSR_16, shape torch.Size([1, 115, 142, 149]), rank 0\n",
      "2025-10-28 01:03:24.064198: predicting IBSR_18\n",
      "2025-10-28 01:03:24.893101: IBSR_18, shape torch.Size([1, 121, 154, 148]), rank 0\n",
      "2025-10-28 01:05:05.714247: Validation complete\n",
      "2025-10-28 01:05:05.721880: Mean Validation Dice:  0.9133465275105349\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_train Dataset001_IBSR18 2d 2 -tr nnUNetTrainer_Fast --npz # FOLD 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c45f5c95-3da4-49cf-80d5-6b180267a879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-10-28 01:06:40.460768: Using torch.compile...\n",
      "2025-10-28 01:06:43.157297: do_dummy_2d_data_aug: False\n",
      "2025-10-28 01:06:43.167215: Using splits from existing split file: /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/data/nnUNet_preprocessed/Dataset001_IBSR18/splits_final.json\n",
      "2025-10-28 01:06:43.174778: The split file contains 5 splits.\n",
      "2025-10-28 01:06:43.179557: Desired fold for training: 3\n",
      "2025-10-28 01:06:43.184137: This split has 12 training and 3 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 2d\n",
      " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 69, 'patch_size': [160, 160], 'median_image_size_in_voxels': [139.0, 147.0], 'spacing': [0.9375, 0.9375], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset001_IBSR18', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.5, 0.9375, 0.9375], 'original_median_shape_after_transp': [115, 137, 144], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 782.0, 'mean': 91.25938415527344, 'median': 69.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 602.0, 'std': 99.86860656738281}}} \n",
      "\n",
      "2025-10-28 01:06:54.004828: Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "2025-10-28 01:06:54.422062: \n",
      "2025-10-28 01:06:54.442553: Epoch 0\n",
      "2025-10-28 01:06:54.462127: Current learning rate: 0.01\n",
      "2025-10-28 01:09:49.134927: train_loss -0.2674\n",
      "2025-10-28 01:09:49.147617: val_loss -0.5995\n",
      "2025-10-28 01:09:49.158243: Pseudo dice [np.float32(0.7244), np.float32(0.8781), np.float32(0.878)]\n",
      "2025-10-28 01:09:49.168347: Epoch time: 174.71 s\n",
      "2025-10-28 01:09:49.181876: Yayy! New best EMA pseudo Dice: 0.8267999887466431\n",
      "2025-10-28 01:09:52.814251: \n",
      "2025-10-28 01:09:52.825636: Epoch 1\n",
      "2025-10-28 01:09:52.837982: Current learning rate: 0.0091\n",
      "2025-10-28 01:12:13.167758: train_loss -0.6812\n",
      "2025-10-28 01:12:13.180618: val_loss -0.7406\n",
      "2025-10-28 01:12:13.190465: Pseudo dice [np.float32(0.8894), np.float32(0.9081), np.float32(0.8975)]\n",
      "2025-10-28 01:12:13.204264: Epoch time: 140.35 s\n",
      "2025-10-28 01:12:13.218206: Yayy! New best EMA pseudo Dice: 0.8339999914169312\n",
      "2025-10-28 01:12:16.438471: \n",
      "2025-10-28 01:12:16.451398: Epoch 2\n",
      "2025-10-28 01:12:16.462965: Current learning rate: 0.00818\n",
      "2025-10-28 01:14:37.059531: train_loss -0.7617\n",
      "2025-10-28 01:14:37.071476: val_loss -0.7768\n",
      "2025-10-28 01:14:37.084079: Pseudo dice [np.float32(0.9065), np.float32(0.9186), np.float32(0.9089)]\n",
      "2025-10-28 01:14:37.097936: Epoch time: 140.62 s\n",
      "2025-10-28 01:14:37.107061: Yayy! New best EMA pseudo Dice: 0.84170001745224\n",
      "2025-10-28 01:14:40.542192: \n",
      "2025-10-28 01:14:40.549148: Epoch 3\n",
      "2025-10-28 01:14:40.555454: Current learning rate: 0.00725\n",
      "2025-10-28 01:17:01.676190: train_loss -0.7898\n",
      "2025-10-28 01:17:01.691370: val_loss -0.7882\n",
      "2025-10-28 01:17:01.700679: Pseudo dice [np.float32(0.9099), np.float32(0.9214), np.float32(0.9128)]\n",
      "2025-10-28 01:17:01.711030: Epoch time: 141.14 s\n",
      "2025-10-28 01:17:01.720901: Yayy! New best EMA pseudo Dice: 0.8489999771118164\n",
      "2025-10-28 01:17:04.845022: \n",
      "2025-10-28 01:17:04.851913: Epoch 4\n",
      "2025-10-28 01:17:04.859102: Current learning rate: 0.00631\n",
      "2025-10-28 01:19:27.487240: train_loss -0.8054\n",
      "2025-10-28 01:19:27.500201: val_loss -0.8021\n",
      "2025-10-28 01:19:27.513973: Pseudo dice [np.float32(0.9127), np.float32(0.9261), np.float32(0.9191)]\n",
      "2025-10-28 01:19:27.526838: Epoch time: 142.64 s\n",
      "2025-10-28 01:19:27.538253: Yayy! New best EMA pseudo Dice: 0.8561000227928162\n",
      "2025-10-28 01:19:30.819474: \n",
      "2025-10-28 01:19:30.829526: Epoch 5\n",
      "2025-10-28 01:19:30.835325: Current learning rate: 0.00536\n",
      "2025-10-28 01:21:53.460158: train_loss -0.8148\n",
      "2025-10-28 01:21:53.473672: val_loss -0.8044\n",
      "2025-10-28 01:21:53.486050: Pseudo dice [np.float32(0.9154), np.float32(0.9271), np.float32(0.9188)]\n",
      "2025-10-28 01:21:53.498589: Epoch time: 142.64 s\n",
      "2025-10-28 01:21:53.513635: Yayy! New best EMA pseudo Dice: 0.862500011920929\n",
      "2025-10-28 01:21:56.643916: \n",
      "2025-10-28 01:21:56.652676: Epoch 6\n",
      "2025-10-28 01:21:56.659709: Current learning rate: 0.00438\n",
      "2025-10-28 01:24:17.233839: train_loss -0.8226\n",
      "2025-10-28 01:24:17.245954: val_loss -0.8069\n",
      "2025-10-28 01:24:17.254497: Pseudo dice [np.float32(0.9152), np.float32(0.9282), np.float32(0.9206)]\n",
      "2025-10-28 01:24:17.264512: Epoch time: 140.59 s\n",
      "2025-10-28 01:24:17.276260: Yayy! New best EMA pseudo Dice: 0.868399977684021\n",
      "2025-10-28 01:24:20.713399: \n",
      "2025-10-28 01:24:20.721124: Epoch 7\n",
      "2025-10-28 01:24:20.730043: Current learning rate: 0.00338\n",
      "2025-10-28 01:26:41.269900: train_loss -0.8272\n",
      "2025-10-28 01:26:41.280173: val_loss -0.81\n",
      "2025-10-28 01:26:41.291064: Pseudo dice [np.float32(0.9145), np.float32(0.9293), np.float32(0.923)]\n",
      "2025-10-28 01:26:41.305941: Epoch time: 140.56 s\n",
      "2025-10-28 01:26:41.317116: Yayy! New best EMA pseudo Dice: 0.8737999796867371\n",
      "2025-10-28 01:26:44.621520: \n",
      "2025-10-28 01:26:44.631780: Epoch 8\n",
      "2025-10-28 01:26:44.641824: Current learning rate: 0.00235\n",
      "2025-10-28 01:29:04.722704: train_loss -0.8302\n",
      "2025-10-28 01:29:04.734769: val_loss -0.81\n",
      "2025-10-28 01:29:04.747162: Pseudo dice [np.float32(0.916), np.float32(0.9289), np.float32(0.9222)]\n",
      "2025-10-28 01:29:04.758695: Epoch time: 140.1 s\n",
      "2025-10-28 01:29:04.771192: Yayy! New best EMA pseudo Dice: 0.878600001335144\n",
      "2025-10-28 01:29:10.545158: \n",
      "2025-10-28 01:29:10.553441: Epoch 9\n",
      "2025-10-28 01:29:10.559874: Current learning rate: 0.00126\n",
      "2025-10-28 01:31:28.960825: train_loss -0.8326\n",
      "2025-10-28 01:31:28.972273: val_loss -0.8116\n",
      "2025-10-28 01:31:28.982008: Pseudo dice [np.float32(0.9166), np.float32(0.9301), np.float32(0.9233)]\n",
      "2025-10-28 01:31:28.994067: Epoch time: 138.42 s\n",
      "2025-10-28 01:31:29.006444: Yayy! New best EMA pseudo Dice: 0.8830999732017517\n",
      "2025-10-28 01:31:33.391533: Training done.\n",
      "2025-10-28 01:31:33.474472: Using splits from existing split file: /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/data/nnUNet_preprocessed/Dataset001_IBSR18/splits_final.json\n",
      "2025-10-28 01:31:33.487381: The split file contains 5 splits.\n",
      "2025-10-28 01:31:33.495441: Desired fold for training: 3\n",
      "2025-10-28 01:31:33.510485: This split has 12 training and 3 validation cases.\n",
      "2025-10-28 01:31:33.519336: predicting IBSR_06\n",
      "2025-10-28 01:31:33.768264: IBSR_06, shape torch.Size([1, 119, 142, 136]), rank 0\n",
      "2025-10-28 01:31:42.416335: predicting IBSR_12\n",
      "2025-10-28 01:31:43.035806: IBSR_12, shape torch.Size([1, 111, 142, 153]), rank 0\n",
      "2025-10-28 01:31:45.586695: predicting IBSR_17\n",
      "2025-10-28 01:31:46.463636: IBSR_17, shape torch.Size([1, 120, 147, 153]), rank 0\n",
      "2025-10-28 01:33:27.229384: Validation complete\n",
      "2025-10-28 01:33:27.236167: Mean Validation Dice:  0.9296918732867736\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_train Dataset001_IBSR18 2d 3 -tr nnUNetTrainer_Fast --npz # FOLD 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1bd178ba-5589-4aa5-94e1-5326a94f6c9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-10-28 01:36:03.238420: Using torch.compile...\n",
      "2025-10-28 01:36:06.155851: do_dummy_2d_data_aug: False\n",
      "2025-10-28 01:36:06.169494: Using splits from existing split file: /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/data/nnUNet_preprocessed/Dataset001_IBSR18/splits_final.json\n",
      "2025-10-28 01:36:06.177974: The split file contains 5 splits.\n",
      "2025-10-28 01:36:06.182968: Desired fold for training: 4\n",
      "2025-10-28 01:36:06.188682: This split has 12 training and 3 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 2d\n",
      " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 69, 'patch_size': [160, 160], 'median_image_size_in_voxels': [139.0, 147.0], 'spacing': [0.9375, 0.9375], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset001_IBSR18', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.5, 0.9375, 0.9375], 'original_median_shape_after_transp': [115, 137, 144], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 782.0, 'mean': 91.25938415527344, 'median': 69.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 602.0, 'std': 99.86860656738281}}} \n",
      "\n",
      "2025-10-28 01:36:19.141926: Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "2025-10-28 01:36:19.654780: \n",
      "2025-10-28 01:36:19.684521: Epoch 0\n",
      "2025-10-28 01:36:19.709122: Current learning rate: 0.01\n",
      "2025-10-28 01:39:25.985943: train_loss -0.29\n",
      "2025-10-28 01:39:26.005715: val_loss -0.6264\n",
      "2025-10-28 01:39:26.016480: Pseudo dice [np.float32(0.6736), np.float32(0.8969), np.float32(0.8716)]\n",
      "2025-10-28 01:39:26.029197: Epoch time: 186.33 s\n",
      "2025-10-28 01:39:26.047098: Yayy! New best EMA pseudo Dice: 0.8141000270843506\n",
      "2025-10-28 01:39:30.002376: \n",
      "2025-10-28 01:39:30.018801: Epoch 1\n",
      "2025-10-28 01:39:30.031627: Current learning rate: 0.0091\n",
      "2025-10-28 01:41:53.517628: train_loss -0.6975\n",
      "2025-10-28 01:41:53.532139: val_loss -0.7469\n",
      "2025-10-28 01:41:53.547873: Pseudo dice [np.float32(0.8346), np.float32(0.9185), np.float32(0.8956)]\n",
      "2025-10-28 01:41:53.561238: Epoch time: 143.52 s\n",
      "2025-10-28 01:41:53.576564: Yayy! New best EMA pseudo Dice: 0.820900022983551\n",
      "2025-10-28 01:41:56.842553: \n",
      "2025-10-28 01:41:56.850359: Epoch 2\n",
      "2025-10-28 01:41:56.859197: Current learning rate: 0.00818\n",
      "2025-10-28 01:44:22.697949: train_loss -0.7675\n",
      "2025-10-28 01:44:22.713564: val_loss -0.7746\n",
      "2025-10-28 01:44:22.725134: Pseudo dice [np.float32(0.8488), np.float32(0.9261), np.float32(0.9036)]\n",
      "2025-10-28 01:44:22.737539: Epoch time: 145.86 s\n",
      "2025-10-28 01:44:22.747578: Yayy! New best EMA pseudo Dice: 0.8281000256538391\n",
      "2025-10-28 01:44:26.011325: \n",
      "2025-10-28 01:44:26.019432: Epoch 3\n",
      "2025-10-28 01:44:26.028643: Current learning rate: 0.00725\n",
      "2025-10-28 01:46:47.306046: train_loss -0.793\n",
      "2025-10-28 01:46:47.318772: val_loss -0.7927\n",
      "2025-10-28 01:46:47.330192: Pseudo dice [np.float32(0.8617), np.float32(0.931), np.float32(0.909)]\n",
      "2025-10-28 01:46:47.341105: Epoch time: 141.3 s\n",
      "2025-10-28 01:46:47.351024: Yayy! New best EMA pseudo Dice: 0.8353999853134155\n",
      "2025-10-28 01:46:50.534195: \n",
      "2025-10-28 01:46:50.542189: Epoch 4\n",
      "2025-10-28 01:46:50.549820: Current learning rate: 0.00631\n",
      "2025-10-28 01:49:18.714314: train_loss -0.8073\n",
      "2025-10-28 01:49:18.727441: val_loss -0.7982\n",
      "2025-10-28 01:49:18.740492: Pseudo dice [np.float32(0.8652), np.float32(0.9326), np.float32(0.912)]\n",
      "2025-10-28 01:49:18.753308: Epoch time: 148.18 s\n",
      "2025-10-28 01:49:18.769360: Yayy! New best EMA pseudo Dice: 0.842199981212616\n",
      "2025-10-28 01:49:21.913526: \n",
      "2025-10-28 01:49:21.920175: Epoch 5\n",
      "2025-10-28 01:49:21.926855: Current learning rate: 0.00536\n",
      "2025-10-28 01:51:59.034683: train_loss -0.8161\n",
      "2025-10-28 01:51:59.050559: val_loss -0.8065\n",
      "2025-10-28 01:51:59.062961: Pseudo dice [np.float32(0.8686), np.float32(0.9355), np.float32(0.9159)]\n",
      "2025-10-28 01:51:59.076396: Epoch time: 157.12 s\n",
      "2025-10-28 01:51:59.090317: Yayy! New best EMA pseudo Dice: 0.8485999703407288\n",
      "2025-10-28 01:52:02.412386: \n",
      "2025-10-28 01:52:02.420768: Epoch 6\n",
      "2025-10-28 01:52:02.429208: Current learning rate: 0.00438\n",
      "2025-10-28 01:54:30.335844: train_loss -0.8225\n",
      "2025-10-28 01:54:30.348518: val_loss -0.8081\n",
      "2025-10-28 01:54:30.361578: Pseudo dice [np.float32(0.8651), np.float32(0.9371), np.float32(0.9179)]\n",
      "2025-10-28 01:54:30.373663: Epoch time: 147.92 s\n",
      "2025-10-28 01:54:30.385071: Yayy! New best EMA pseudo Dice: 0.8543999791145325\n",
      "2025-10-28 01:54:33.611067: \n",
      "2025-10-28 01:54:33.619453: Epoch 7\n",
      "2025-10-28 01:54:33.627910: Current learning rate: 0.00338\n",
      "2025-10-28 01:56:56.941265: train_loss -0.8266\n",
      "2025-10-28 01:56:56.953276: val_loss -0.8101\n",
      "2025-10-28 01:56:56.964097: Pseudo dice [np.float32(0.8684), np.float32(0.9368), np.float32(0.9182)]\n",
      "2025-10-28 01:56:56.975441: Epoch time: 143.33 s\n",
      "2025-10-28 01:56:56.987027: Yayy! New best EMA pseudo Dice: 0.8597999811172485\n",
      "2025-10-28 01:57:00.208425: \n",
      "2025-10-28 01:57:00.215396: Epoch 8\n",
      "2025-10-28 01:57:00.221241: Current learning rate: 0.00235\n",
      "2025-10-28 01:59:24.583050: train_loss -0.8293\n",
      "2025-10-28 01:59:24.594794: val_loss -0.8113\n",
      "2025-10-28 01:59:24.607426: Pseudo dice [np.float32(0.868), np.float32(0.9376), np.float32(0.9197)]\n",
      "2025-10-28 01:59:24.617928: Epoch time: 144.38 s\n",
      "2025-10-28 01:59:24.630691: Yayy! New best EMA pseudo Dice: 0.8646000027656555\n",
      "2025-10-28 01:59:30.348139: \n",
      "2025-10-28 01:59:30.356367: Epoch 9\n",
      "2025-10-28 01:59:30.363834: Current learning rate: 0.00126\n",
      "2025-10-28 02:01:52.724524: train_loss -0.8316\n",
      "2025-10-28 02:01:52.737665: val_loss -0.8162\n",
      "2025-10-28 02:01:52.749522: Pseudo dice [np.float32(0.8716), np.float32(0.9391), np.float32(0.9216)]\n",
      "2025-10-28 02:01:52.762720: Epoch time: 142.38 s\n",
      "2025-10-28 02:01:52.773986: Yayy! New best EMA pseudo Dice: 0.8691999912261963\n",
      "2025-10-28 02:01:57.163939: Training done.\n",
      "2025-10-28 02:01:57.250542: Using splits from existing split file: /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/data/nnUNet_preprocessed/Dataset001_IBSR18/splits_final.json\n",
      "2025-10-28 02:01:57.259199: The split file contains 5 splits.\n",
      "2025-10-28 02:01:57.268501: Desired fold for training: 4\n",
      "2025-10-28 02:01:57.275890: This split has 12 training and 3 validation cases.\n",
      "2025-10-28 02:01:57.283990: predicting IBSR_03\n",
      "2025-10-28 02:01:57.523610: IBSR_03, shape torch.Size([1, 111, 131, 143]), rank 0\n",
      "2025-10-28 02:02:40.508245: predicting IBSR_04\n",
      "2025-10-28 02:02:41.903118: IBSR_04, shape torch.Size([1, 116, 134, 151]), rank 0\n",
      "2025-10-28 02:02:47.671381: predicting IBSR_07\n",
      "2025-10-28 02:02:48.637413: IBSR_07, shape torch.Size([1, 113, 137, 141]), rank 0\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/spawn.py\", line 125, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"/usr/lib/python3.10/multiprocessing/spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 289, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 96, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/mnt/c/Users/abdal/Documents/Projects/ai-notebooks/env/bin/nnUNetv2_train\", line 5, in <module>\n",
      "    from nnunetv2.run.run_training import run_training_entry\n",
      "  File \"/mnt/c/Users/abdal/Documents/Projects/ai-notebooks/nnUNet/nnunetv2/run/run_training.py\", line 13, in <module>\n",
      "    from nnunetv2.training.nnUNetTrainer.nnUNetTrainer import nnUNetTrainer\n",
      "  File \"/mnt/c/Users/abdal/Documents/Projects/ai-notebooks/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 48, in <module>\n",
      "    from nnunetv2.inference.export_prediction import export_prediction_from_logits, resample_and_save\n",
      "  File \"/mnt/c/Users/abdal/Documents/Projects/ai-notebooks/nnUNet/nnunetv2/inference/export_prediction.py\", line 9, in <module>\n",
      "    from nnunetv2.training.dataloading.nnunet_dataset import nnUNetDatasetBlosc2\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1002, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 945, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1439, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1411, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1548, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1591, in _fill_cache\n",
      "OSError: [Errno 12] Cannot allocate memory: '/mnt/c/Users/abdal/Documents/Projects/ai-notebooks/nnUNet/nnunetv2/training/dataloading'\n",
      "2025-10-28 02:04:39.679008: Validation complete\n",
      "2025-10-28 02:04:39.703192: Mean Validation Dice:  0.9136672133644957\n"
     ]
    }
   ],
   "source": [
    "!nnUNetv2_train Dataset001_IBSR18 2d 4 -tr nnUNetTrainer_Fast --npz # FOLD 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5283966-2ba4-46a3-b7d2-c35a282a08e9",
   "metadata": {},
   "source": [
    "Automatically determine the best configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0557178d-6af6-4f45-b3db-d853d88e9857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: nnUNetv2_find_best_configuration [-h] [-p P [P ...]] [-c C [C ...]]\n",
      "                                        [-tr TR [TR ...]] [-np NP]\n",
      "                                        [-f F [F ...]] [--disable_ensembling]\n",
      "                                        [--no_overwrite]\n",
      "                                        dataset_name_or_id\n",
      "\n",
      "positional arguments:\n",
      "  dataset_name_or_id    Dataset Name or id\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -p P [P ...]          List of plan identifiers. Default: nnUNetPlans\n",
      "  -c C [C ...]          List of configurations. Default: ['2d', '3d_fullres',\n",
      "                        '3d_lowres', '3d_cascade_fullres']\n",
      "  -tr TR [TR ...]       List of trainers. Default: nnUNetTrainer\n",
      "  -np NP                Number of processes to use for ensembling,\n",
      "                        postprocessing etc\n",
      "  -f F [F ...]          Folds to use. Default: 0 1 2 3 4\n",
      "  --disable_ensembling  Set this flag to disable ensembling\n",
      "  --no_overwrite        If set we will not overwrite already ensembled files\n",
      "                        etc. May speed up consecutive runs of this command\n",
      "                        (why would you want to do that?) at the risk of not\n",
      "                        updating outdated results.\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/how_to_use_nnunet.md#automatically-determine-the-best-configuration\n",
    "!nnUNetv2_find_best_configuration -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4ae80db0-16c8-4d72-a773-eb0317ef7e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***All results:***\n",
      "nnUNetTrainer_Fast__nnUNetPlans__2d: 0.9232307202265632\n",
      "\n",
      "*Best*: nnUNetTrainer_Fast__nnUNetPlans__2d: 0.9232307202265632\n",
      "\n",
      "***Determining postprocessing for best model/ensemble***\n",
      "Removing all but the largest foreground region did not improve results!\n",
      "Removing all but the largest component for 1 did not improve results! Dice before: 0.89786 after: 0.83744\n",
      "Results were improved by removing all but the largest component for 2. Dice before: 0.94053 after: 0.94057\n",
      "Removing all but the largest component for 3 did not improve results! Dice before: 0.9313 after: 0.8908\n",
      "\n",
      "***Run inference like this:***\n",
      "\n",
      "nnUNetv2_predict -d Dataset001_IBSR18 -i INPUT_FOLDER -o OUTPUT_FOLDER -f  0 1 2 3 4 -tr nnUNetTrainer_Fast -c 2d -p nnUNetPlans\n",
      "\n",
      "***Once inference is completed, run postprocessing like this:***\n",
      "\n",
      "nnUNetv2_apply_postprocessing -i OUTPUT_FOLDER -o OUTPUT_FOLDER_PP -pp_pkl_file /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/data/nnUNet_results/Dataset001_IBSR18/nnUNetTrainer_Fast__nnUNetPlans__2d/crossval_results_folds_0_1_2_3_4/postprocessing.pkl -np 8 -plans_json /mnt/c/Users/abdal/Documents/Projects/ai-notebooks/data/nnUNet_results/Dataset001_IBSR18/nnUNetTrainer_Fast__nnUNetPlans__2d/crossval_results_folds_0_1_2_3_4/plans.json\n"
     ]
    }
   ],
   "source": [
    "# nnUNetv2_find_best_configuration DATASET_NAME_OR_ID -c CONFIGURATIONS \n",
    "# we also added our custom trainer in the command\n",
    "!nnUNetv2_find_best_configuration Dataset001_IBSR18 -c 2d -tr nnUNetTrainer_Fast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c74f382-c352-43da-bab6-704b382e23e6",
   "metadata": {},
   "source": [
    "Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e4e319-7706-4883-8df4-32b5fb534f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/how_to_use_nnunet.md#run-inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
